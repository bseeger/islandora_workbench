#!/usr/bin/env python3

# Usage: ./workbench --config config.yml

import os
import sys
import copy
import json
import csv
import logging
import datetime
import argparse
from workbench_utils import *


def create():
    """Create new nodes via POST, and add media if there are any.
    """
    logging.info('"Create" task started using config file %s', args.config)
    input_csv = os.path.join(config['input_dir'], config['input_csv'])
    if os.path.exists(input_csv):
        # Store a dict of id_field: node IDs so we can add linked nodes.
        # This dict is not currently used but could be for things like
        # https://github.com/mjordan/islandora_workbench/issues/18.
        node_ids = dict()

        field_definitions = get_field_definitions(config)
        # Exit when we're just testing field definitions.
        sys.exit()
        with open(input_csv) as csvfile:
            csv_data = csv.DictReader(csvfile, delimiter=config['delimiter'])
            csv_column_headers = csv_data.fieldnames

            node_endpoint = config['host'] + '/node?_format=json'

            for row in csv_data:
                row = clean_csv_values(row)

                id_field = row[config['id_field']]

                # Add required fields.
                node = {
                    'type': [
                        {'target_id': config['content_type'],
                         'target_type': 'node_type'}
                    ],
                    'title': [
                        {'value': row['title']}
                    ],
                    'status': [
                        {'value': config['published']}
                    ]
                }

                # Add custom (non-required) CSV fields.
                required_fields = ['file', config['id_field'], 'title']
                custom_fields = list(
                    set(csv_column_headers)-set(required_fields))
                for custom_field in custom_fields:
                    if not isinstance(row[custom_field], str):
                        continue
                    # Skip updating field if value is empty.
                    if len(row[custom_field]) == 0:
                        continue

                    # Execute field preprocessor scripts, if any are configured. Note that these scripts
                    # are applied to the entire value from the CSV field and not split field values,
                    # e.g., if a field is multivalued, the preprocesor must split it and then reassemble
                    # it back into a string before returning it. Note that preprocessor scripts work only
                    # on string data and not on binary data like images, etc. and only on custom fields
                    # (so not title).
                    if 'preprocessors' in config and len(config['preprocessors']) > 0:
                        for field, command in config['preprocessors'].items():
                            if field in csv_column_headers:
                                output, return_code = preprocess_field_data(config['subdelimiter'], row[field], command)
                                if return_code == 0:
                                    preprocessor_input = copy.deepcopy(row[field])
                                    row[field] = output.decode().strip()
                                    logging.info('Preprocess command %s executed, taking "%s" as input and returning "%s".', command, preprocessor_input, output.decode().strip())
                                else:
                                    logging.error('Preprocess command %s failed with return code %s.', command, return_code)

                    # Assemble Drupal field structures for entity reference fields from CSV data. For
                    # taxonomy terms, target_type is 'taxonomy_term'; for nodes, it's 'node_type'.
                    if field_definitions[custom_field]['field_type'] == 'entity_reference':
                        if field_definitions[custom_field]['target_type'] == 'taxonomy_term':
                            target_type = 'taxonomy_term'
                            # Get the field's linked vocabularies so we can determine whether a non-
                            # numeric value in this field already exists in the linked vocabulary.
                            linked_vocabularies = field_definitions[custom_field]['vocabularies']
                        if field_definitions[custom_field]['target_type'] == 'node':
                            target_type = 'node_type'
                        # Cardinality is unlimited.
                        if field_definitions[custom_field]['cardinality'] == -1:
                            if config['subdelimiter'] in row[custom_field]:
                                field_values = []
                                subvalues = row[custom_field].split(config['subdelimiter'])
                                for subvalue in subvalues:
                                    field_values.append({'target_id': subvalue, 'target_type': target_type})
                                    # Issue 61: For taxonomy_term fields: If the subvalue is not numeric,
                                    # we need to get the field's target vocabulary, and for multi-vocabulary
                                    # fields, make sure the incoming data contains the target vocabulary ID. Then,
                                    # check that the subvalue exists in the target vocabulary. If it does, get its
                                    # term ID; if it doesn't, add it to the vocabulary and then get its term ID.
                                node[custom_field] = field_values
                            else:
                                node[custom_field] = [
                                                      {'target_id': row[custom_field],
                                                       'target_type': target_type}]
                        elif field_definitions[custom_field]['cardinality'] > 1:
                            if config['subdelimiter'] in row[custom_field]:
                                field_values = []
                                subvalues = row[custom_field].split(config['subdelimiter'])
                                # @todo: log fact that we're slicing off values.
                                for subvalue in subvalues:
                                    field_values.append({'target_id': subvalue, 'target_type': target_type})
                                    # Issue 61: For taxonomy_term fields: If the subvalue is not numeric,
                                    # we need to get the field's target vocabulary, and for multi-vocabulary
                                    # fields, make sure the incoming data contains the target vocabulary ID. Then,
                                    # check that the subvalue exists in the target vocabulary. If it does, get its
                                    # term ID; if it doesn't, add it to the vocabulary and then get its term ID.
                                # @todo: log fact that we're slicing off values.
                                node[custom_field] = field_values[:field_definitions[custom_field]['cardinality']]
                            else:
                                # Issue 61: For taxonomy_term fields: If the subvalue is not numeric,
                                # we need to get the field's target vocabulary, and for multi-vocabulary
                                # fields, make sure the incoming data contains the target vocabulary ID. Then,
                                # check that the subvalue exists in the target vocabulary. If it does, get its
                                # term ID; if it doesn't, add it to the vocabulary and then get its term ID.
                                node[custom_field] = [
                                                      {'target_id': row[custom_field],
                                                       'target_type': target_type}]
                        # Cardinality is 1.
                        else:
                            # Issue 61: For taxonomy_term fields: If the subvalue is not numeric,
                            # we need to get the field's target vocabulary, and for multi-vocabulary
                            # fields, make sure the incoming data contains the target vocabulary ID. Then,
                            # check that the subvalue exists in the target vocabulary. If it does, get its
                            # term ID; if it doesn't, add it to the vocabulary and then get its term ID.
                            node[custom_field] = [
                                                  {'target_id': row[custom_field],
                                                   'target_type': target_type}]

                    # Typed relation fields.
                    elif field_definitions[custom_field]['field_type'] == 'typed_relation':
                        target_type = field_definitions[custom_field]['target_type']
                        # Cardinality is unlimited.
                        if field_definitions[custom_field]['cardinality'] == -1:
                            if config['subdelimiter'] in row[custom_field]:
                                field_values = []
                                subvalues = split_typed_relation_string(config, row[custom_field], target_type)
                                for subvalue in subvalues:
                                    field_values.append(subvalue)
                                node[custom_field] = field_values
                            else:
                                field_value = split_typed_relation_string(config, row[custom_field], target_type)
                                node[custom_field] = field_value

                        # Cardinality has a limit.
                        elif field_definitions[custom_field]['cardinality'] > 1:
                            if config['subdelimiter'] in row[custom_field]:
                                field_values = []
                                subvalues = split_typed_relation_string(config, row[custom_field], target_type)
                                subvalues = subvalues[:field_definitions[custom_field]['cardinality']]
                                for subvalue in subvalues:
                                        field_values.append(subvalue)
                                node[custom_field] = field_values
                            else:
                                field_value = split_typed_relation_string(config, row[custom_field], target_type)
                                node[custom_field] = field_value
                        # Cardinality is 1.
                        else:
                            field_values = split_typed_relation_string(config, row[custom_field], target_type)
                            node[custom_field] = field_value[0]
                            logging.warning("Adding all values in CSV field %s for record %s would exceed maximum number of allowed values (1), so only adding first value.", row[custom_field], id_field)

                    # For non-entity reference and non-typed relation fields (text, etc.).
                    else:
                        # Cardinality is unlimited.
                        if field_definitions[custom_field]['cardinality'] == -1:
                            if config['subdelimiter'] in row[custom_field]:
                                field_values = []
                                subvalues = row[custom_field].split(config['subdelimiter'])
                                for subvalue in subvalues:
                                    field_values.append({'value': subvalue})
                                    node[custom_field] = field_values
                                else:
                                    node[custom_field] = [{'value': row[custom_field]}]
                            else:
                                node[custom_field] = [{'value': row[custom_field]}]
                        elif field_definitions[custom_field]['cardinality'] > 1:
                            if config['subdelimiter'] in row[custom_field]:
                                field_values = []
                                subvalues = row[custom_field].split(config['subdelimiter'])
                                # @todo: log fact that we're slicing off values.
                                subvalues = subvalues[:field_definitions[custom_field]['cardinality']]
                                for subvalue in subvalues:
                                    field_values.append({'value': subvalue})
                                node[custom_field] = field_values
                            else:
                                node[custom_field] = [{'value': row[custom_field]}]
                        # Cardinality is 1.
                        else:
                            node[custom_field] = [{'value': row[custom_field]}]

                node_headers = {
                    'Content-Type': 'application/json'
                }
                node_endpoint = '/node?_format=json'
                node_response = issue_request(config, 'POST', node_endpoint, node_headers, node, None)
                if node_response.status_code == 201:
                    node_uri = node_response.headers['location']
                    print("Node for '" + row['title'] +
                          "' (record " + id_field + ") created at " + node_uri + ".")
                    logging.info("Node for %s (record %s) created at %s.", row['title'], id_field, node_uri)
                else:
                    logging.warning("Node for CSV record %s not created, HTTP response code was %s.", id_field, node_response.status_code)
                    continue

                # Get ID of newly created node so we can use it for linking
                # child nodes, etc.
                if node_response.status_code == 201:
                    node_id = node_uri.rsplit('/', 1)[-1]
                    node_ids[id_field] = node_id

                # If there is no media file, move on to the next CSV row.
                if len(row['file']) == 0:
                    print("+No media for " + node_uri + " created since " +
                          "its 'file' field in the CSV is empty.")
                    logging.warning("No media for %s created since its " +
                                    "'file' field in the CSV is empty.", node_uri)
                    continue

                # If there is a media file, add it.
                file_path = os.path.join(config['input_dir'], row['file'])
                mimetype = mimetypes.guess_type(file_path)
                media_type = set_media_type(mimetype[0])

                if node_response.status_code == 201 and len(row['file']) != 0:
                    media_response_status_code = create_media(config, row['file'], node_uri)
                    allowed_media_response_codes = [201, 204]
                    if media_response_status_code in allowed_media_response_codes:
                        print('+' + media_type.title() + " media for " +
                              row['file'] + " created.")
                        logging.info("%s media for %s created.", media_type.title(), row['file'])

                if node_response.status_code == 201 and len(row['file']) == 0:
                    print('+ No file specified in CSV for ' + row['title'])


def update():
    """Update nodes via PATCH. Note that PATCHing replaces the target field,
       so if we are adding an additional value to a multivalued field, we need
       to include the existing value(s) in our PATCH.
    """
    input_csv = os.path.join(config['input_dir'], config['input_csv'])
    if os.path.exists(input_csv):
        field_definitions = get_field_definitions(config)
        with open(input_csv) as csvfile:
            csv_data = csv.DictReader(csvfile, delimiter=config['delimiter'])
            csv_column_headers = csv_data.fieldnames

            for row in csv_data:
                row = clean_csv_values(row)
                if not ping_node(config, row['node_id']):
                    print("Node " + row['node_id'] + " not found or not " +
                          "accessible, skipping update.")
                    continue

                # Add the target_id field.
                node = {
                    'type': [
                        {'target_id': config['content_type']}
                    ]
                }

                node_field_values = get_node_field_values(config, row['node_id'])

                # Add custom (non-required) fields.
                required_fields = ['node_id']
                custom_fields = list(
                    set(csv_column_headers)-set(required_fields))
                for custom_field in custom_fields:
                    # Skip updating field if value is empty.
                    if len(row[custom_field]) == 0:
                        continue

                    # Entity reference fields: for taxonomy terms, target_type is 'taxonomy_term';
                    # for nodes, it's 'node_type'.
                    if field_definitions[custom_field]['field_type'] == 'entity_reference':
                        if field_definitions[custom_field]['target_type'] == 'taxonomy_term':
                            target_type = 'taxonomy_term'
                        if field_definitions[custom_field]['target_type'] == 'node':
                            target_type = 'node_type'

                        if field_definitions[custom_field]['cardinality'] == 1:
                            node[custom_field] = [
                                {'target_id': row[custom_field],
                                 'target_type': target_type}]
                        # Cardinality has a limit.
                        elif field_definitions[custom_field]['cardinality'] > 1:
                            # Append to existing values.
                            existing_target_ids = get_target_ids(node_field_values[custom_field])
                            num_existing_values = len(existing_target_ids)

                            if config['subdelimiter'] in row[custom_field]:
                                field_values = []
                                subvalues = row[custom_field].split(config['subdelimiter'])
                                for subvalue in subvalues:
                                    if subvalue in existing_target_ids:
                                        existing_target_ids.remove(subvalue)
                                # Slice the incoming values to a length that matches the field's
                                # cardinality minus its existing length. Also log fact that we're
                                # slicing off values.
                                num_values_to_add = field_definitions[custom_field]['cardinality'] - num_existing_values
                                subvalues = subvalues[:num_values_to_add]
                                if len(subvalues) > 0:
                                    logging.warning("Adding all values in CSV field %s for node %s would exceed maximum number of allowed values (%s), so only adding %s values.", custom_field, row['node_id'], field_definitions[custom_field]['cardinality'], num_values_to_add)
                                    logging.info("Updating node %s with %s values from CSV record.", row['node_id'], num_values_to_add)
                                    for subvalue in subvalues:
                                        field_values.append({'target_id': subvalue, 'target_type': target_type})
                                    node[custom_field] = node_field_values[custom_field] + field_values
                                else:
                                    logging.info("Not updating field %s node for %s, provided values do not contain any new values for this field.", custom_field, row['node_id'])
                            else:
                                if num_existing_values + 1 <= field_definitions[custom_field]['cardinality']:
                                    node[custom_field] = node_field_values[custom_field] + [
                                        {'target_id': row[custom_field],
                                         'target_type': 'taxonomy_term'}]
                                else:
                                    logging.warning("Not updating field %s node for %s, adding provided value would exceed maxiumum number of allowed values.", custom_field, row['node_id'])
                        # Cardinality is unlimited.
                        else:
                            # Append to existing values.
                            if config['subdelimiter'] in row[custom_field]:
                                field_values = []
                                subvalues = row[custom_field].split(config['subdelimiter'])
                                for subvalue in subvalues:
                                    field_values.append({'target_id': subvalue, 'target_type': target_type})
                                    node[custom_field] = node_field_values[custom_field] + field_values
                            else:
                                node[custom_field] = node_field_values[custom_field] + [
                                    {'target_id': row[custom_field],
                                     'target_type': 'taxonomy_term'}]

                    # Typed relation fields.
                    elif field_definitions[custom_field]['field_type'] == 'typed_relation':
                        # Create a copy of the existing values in the current field so we can compare
                        # them to the incoming values in the CSV file for deduping. To compare these
                        # values with the incoming ones, we need to remove the 'url' and
                        # 'target_uuid' members.
                        node_comparison_values = copy.deepcopy(node_field_values[custom_field])
                        for comparison_value in node_comparison_values:
                            del comparison_value['url']
                            del comparison_value['target_uuid']

                        if field_definitions[custom_field]['target_type'] == 'taxonomy_term':
                            target_type = 'taxonomy_term'
                        if field_definitions[custom_field]['target_type'] == 'node':
                            target_type = 'node_type'
                        # Cardinality is unlimited.
                        if field_definitions[custom_field]['cardinality'] == -1:
                            # Append to existing values.
                            if config['subdelimiter'] in row[custom_field]:
                                field_values = []
                                subvalues = split_typed_relation_string(config, row[custom_field], target_type)
                                for subvalue in subvalues:
                                    field_values.append(subvalue)
                                node[custom_field] = node_field_values[custom_field] + field_values
                            # Append to existing values.
                            else:
                                value = split_typed_relation_string(config, row[custom_field], target_type)
                                node[custom_field] = node_field_values[custom_field] + [value]
                        # Cardinality has a limit.
                        elif field_definitions[custom_field]['cardinality'] > 1:
                            existing_target_ids = get_target_ids(node_field_values[custom_field])
                            num_existing_values = len(existing_target_ids)

                            if config['subdelimiter'] in row[custom_field]:
                                field_values = []
                                subvalues = split_typed_relation_string(config, row[custom_field], target_type)
                                for subvalue in subvalues:
                                    if subvalue not in node_comparison_values:
                                        field_values.append(subvalue)
                                # Slice the incoming values to a length that matches the field's
                                # cardinality minus its existing length. Also log fact that we're
                                # slicing off values.
                                num_values_to_add = field_definitions[custom_field]['cardinality'] - num_existing_values
                                if num_values_to_add > 0:
                                    logging.warning("Adding all values in CSV field %s for node %s would exceed maximum number of allowed values (%s), so only adding %s values.", custom_field, row['node_id'], field_definitions[custom_field]['cardinality'], num_values_to_add)
                                    logging.info("Updating node %s with %s values from CSV record.", row['node_id'], num_values_to_add)
                                    field_values = field_values[:num_values_to_add]
                                    node[custom_field] = node_field_values[custom_field] + field_values
                                else:
                                    logging.info("Not updating field %s node for %s, provided values do not contain any new values for this field.", custom_field, row['node_id'])
                            else:
                                if num_existing_values + 1 <= field_definitions[custom_field]['cardinality']:
                                    field_value = split_typed_relation_string(config, row[custom_field], target_type)
                                    node[custom_field] = node_field_values[custom_field] + field_value
                                else:
                                    logging.warning("Not updating field %s node for %s, adding provided value would exceed maxiumum number of allowed values.", custom_field, row['node_id'])
                        # Cardinality is 1. Do not append to existing values, replace existing value.
                        else:
                            field_values = split_typed_relation_string(config, row[custom_field], target_type)
                            if len(field_values) > 1:
                                node[custom_field] = [field_values[0]]
                                logging.warning("Adding all values in CSV field %s for node %s would exceed maximum number of allowed values (1), so only adding first value.", custom_field, row['node_id'])
                                logging.info("Updating node %s with 1 values from CSV record.", row['node_id'])

                    # For non-entity reference and non-typed relation fields (text, etc.).
                    else:
                        if field_definitions[custom_field]['cardinality'] == 1:
                            node[custom_field] = [{'value': row[custom_field]}]
                        elif field_definitions[custom_field]['cardinality'] > 1:
                            # Append to existing values.
                            if config['subdelimiter'] in row[custom_field]:
                                field_values = []
                                subvalues = row[custom_field].split(config['subdelimiter'])
                                # Slice the incoming values to a length that matches the field's
                                # cardinality minus its existing length. Also log fact that we're
                                # slicing off values. We don't dedupe these values.
                                subvalues = subvalues[:field_definitions[custom_field]['cardinality']]
                                for subvalue in subvalues:
                                    field_values.append({'value': subvalue})
                                    node[custom_field] = node_field_values[custom_field] + field_values
                            else:
                                node[custom_field] = node_field_values[custom_field] + [{'value': row[custom_field]}]
                        # Cardinatlity is unlimited.
                        else:
                            # Append to existing values.
                            if config['subdelimiter'] in row[custom_field]:
                                field_values = []
                                subvalues = row[custom_field].split(config['subdelimiter'])
                                for subvalue in subvalues:
                                    field_values.append({'value': subvalue})
                                    node[custom_field] = node_field_values[custom_field] + field_values
                            else:
                                node[custom_field] = node_field_values[custom_field] + [{'value': row[custom_field]}]

                node_endpoint = config['host'] + '/node/' + row['node_id'] + '?_format=json'
                node_headers = {
                    'Content-Type': 'application/json'
                }
                node_response = issue_request(config, 'PATCH', node_endpoint, node_headers, node)

                if node_response.status_code == 200:
                    print("Node for " + config['host'] + '/node/' +
                          row['node_id'] + " updated.")
                    logging.info("Node for %s updated.", config['host'] + '/node/' + row['node_id'])


def delete():
    """Delete nodes.
    """
    input_csv = os.path.join(config['input_dir'], config['input_csv'])
    if os.path.exists(input_csv):
        with open(input_csv) as csvfile:
            csv_data = csv.DictReader(csvfile)
            csv_column_headers = csv_data.fieldnames

            for row in csv_data:
                row = clean_csv_values(row)
                if not ping_node(config, row['node_id']):
                    print("Node " + row['node_id'] + " not found or not " +
                          "accessible, skipping delete.")
                    continue

                node_endpoint = config['host'] + '/node/' + str(row['node_id']) + '?_format=json'
                node_response = issue_request(config, 'DELETE', node_endpoint)
                if node_response.status_code == 204:
                    print("Node " + config['host'] + '/node/' +
                          str(row['node_id']) + " deleted.")
                    logging.info("Node %s deleted.", config['host'] +
                                 '/node/' + row['node_id'])


def add_media():
    """Add media to existing nodes using PUT.
    """
    input_csv = os.path.join(config['input_dir'], config['input_csv'])
    if os.path.exists(input_csv):
        with open(input_csv) as csvfile:
            csv_data = csv.DictReader(csvfile, delimiter=config['delimiter'])
            csv_column_headers = csv_data.fieldnames

            for row in csv_data:
                row = clean_csv_values(row)
                if not ping_node(config, row['node_id']):
                    print("Node " + row['node_id'] + " not found or not " +
                          "accessible, skipping adding media.")
                    continue

                file_path = os.path.join(config['input_dir'], row['file'])
                mimetype = mimetypes.guess_type(file_path)
                media_type = set_media_type(mimetype[0])

                node_json_url = config['host'] + '/node/' + row['node_id'] + '?_format=json'
                node_uri = config['host'] + '/node/' + row['node_id']
                node_response = issue_request(config, 'GET', node_json_url)
                if node_response.status_code == 200:
                    media_response_status_code = create_media(config, row['file'], node_uri)
                    allowed_media_response_codes = [201, 204]
                    if media_response_status_code in allowed_media_response_codes:
                        print(media_type.title() + " media for " + row['file'] + " created and added to " + node_uri)
                        logging.info("%s media for %s created and added to %s.", media_type.title(), row['file'], node_uri)


# Main program logic.

parser = argparse.ArgumentParser()
parser.add_argument(
    '--config',
    help='Configuration file to use.')
parser.add_argument(
    '--check',
    help='Check input data and exit without creating/updating/etc.', action='store_true')
args = parser.parse_args()

config = set_config_defaults(args)
logging.basicConfig(
    filename=config['log_file_path'],
    level=logging.INFO,
    filemode=config['log_file_mode'],
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%d-%b-%y %H:%M:%S')

if config['check']:
    check_input(config, args)

# Issue 61 testing
# create_term(config, 'islandora_display', "How you doing?")
# foo = get_term_names(config, 'islandora_display')
# print(foo)
# bar = find_term_in_vocab(config, 'islandora_display', 'PDFjs')
# print(bar)

# Execute bootstrap scripts, if any are configured.
if 'bootstrap' in config and len(config['bootstrap']) > 0:
    for command in config['bootstrap']:
        print("Executing bootstrap script " + command)
        output, return_code = execute_bootstrap_script(command, args.config)

if config['task'] == 'create':
    create()
if config['task'] == 'update':
    update()
if config['task'] == 'delete':
    delete()
if config['task'] == 'add_media':
    add_media()
